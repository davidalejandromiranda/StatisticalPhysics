{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bit4234ff425b8345348b82ba841a9698bd",
   "display_name": "Python 3.7.3 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h1 align=\"center\">Procesamiento de muestra de datos del Covid19 en Colombia.</h1>\n",
    "<div align=\"right\">David A. Miranda, PhD<br>2021</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "En este Jypyter Notebook se analiza una muestra de datos de Covid19 extraída de [datos.org.co](https://www.datos.gov.co/Salud-y-Protecci-n-Social/Casos-positivos-de-COVID-19-en-Colombia/gt2j-8ykr/data)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Cargar Librerías"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-69ffa4e65c89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from datetime import datetime"
   ]
  },
  {
   "source": [
    "## 2. Cargar datos\n",
    "### 2.1. Carga datos locales, si tienes clonado el repositorio"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([])\n",
    "try:\n",
    "    data = pd.read_csv('../data/20210411_Covid19_Santander.cvs.zip', low_memory=False)\n",
    "except:\n",
    "    print('Error! There are no local data; try with online data.')"
   ]
  },
  {
   "source": [
    "### 2.2. Carga datos desde la nube"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('https://github.com/davidalejandromiranda/StatisticalPhysics/blob/main/data/20210411_Covid19_Santander.cvs?raw=true', low_memory=False, error_bad_lines=False)\n",
    "except:\n",
    "    print('Error! It was not possible to get online data; please, check your Internet connection.')"
   ]
  },
  {
   "source": [
    "## 3. Descripción de los datos\n",
    "### 3.1. El método *describe()* de pandas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "source": [
    "### 3.2. Columnas en la tabla de datos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "source": [
    "### 3.3. Valores unicos de una columna"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Nombre municipio'].unique()"
   ]
  },
  {
   "source": [
    "### 3.4. Obtención de todas las filas para un valor de una columna"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_buc = data.loc[data['Nombre municipio'] == 'BUCARAMANGA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data['Nombre municipio'] == 'BUCARAMANGA'\n",
    "data_buc = data.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_buc.describe()"
   ]
  },
  {
   "source": [
    "## 4. Análisis de la columna *Recuperado* para datos Covid19\n",
    "### 4.1. Limpieza básica de datos: unificar nombre de columnas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Recuperado'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['Recuperado'] == 'fallecido'] = 'Fallecido'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_labels = data['Recuperado'].unique()\n",
    "status_labels"
   ]
  },
  {
   "source": [
    "### 4.2. Gráfica de cuenta de valores de la columna"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "ax = sns.countplot(y='Recuperado', ax=plt.gca(), data=data)"
   ]
  },
  {
   "source": [
    "### 4.3. Tabla con cuenta de valores de la columna"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Recuperado').describe()"
   ]
  },
  {
   "source": [
    "### 4.4. Procesamiento de cuentas por agrupamiento"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recuperado_data = data.groupby('Recuperado')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_Activo = len(recuperado_data.groups['Activo'])\n",
    "num_Fallecido = len(recuperado_data.groups['Fallecido'])\n",
    "num_Recuperado = len(recuperado_data.groups['Recuperado'])\n",
    "num_Total = num_Activo + num_Fallecido + num_Recuperado"
   ]
  },
  {
   "source": [
    "#### 4.4.1. Organización de datos procesados en una tabla de Pandas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_recuperado = pd.DataFrame({\n",
    "    'Estado':[\n",
    "        'Activos',\n",
    "        'Recuperados',\n",
    "        'Fallecidos'],\n",
    "    '%':[ \n",
    "        100*num_Activo/num_Total,\n",
    "        100*num_Recuperado/num_Total,\n",
    "        100*num_Fallecido/num_Total,\n",
    "        ],\n",
    "})\n",
    "perc_recuperado"
   ]
  },
  {
   "source": [
    "#### 4.4.2. Redondeo de datos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_recuperado['%'] = perc_recuperado.apply(lambda row: np.round(row['%'], 1), axis=1)\n",
    "perc_recuperado"
   ]
  },
  {
   "source": [
    "## 5. Análisis de la columna *Edad* para datos Covid19\n",
    "### 5.1. Limpieza de datos: eliminación de datos inválidos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in data['Edad']:\n",
    "    try:\n",
    "        float(e)\n",
    "    except:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Edad'] = data.apply(lambda row: np.NaN if type(row['Edad']) == type('String') else row['Edad'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in data['Edad']:\n",
    "    try:\n",
    "        float(e)\n",
    "    except:\n",
    "        print(e)"
   ]
  },
  {
   "source": [
    "### 5.2. Diagrama de violín\n",
    "#### 5.2.1. Todos los datos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "_ = sns.violinplot(y='Edad', data=data, ax=plt.gca())"
   ]
  },
  {
   "source": [
    "#### 5.2.2. Por agrupamientos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "_ = sns.violinplot(x='Recuperado', y='Edad', data=data, ax=plt.gca())"
   ]
  },
  {
   "source": [
    "### 5.3. Gráficos Boxplot\n",
    "#### 5.2.1. Todos los datos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "_ = data.boxplot(column='Edad', ax=plt.gca())"
   ]
  },
  {
   "source": [
    "#### 5.3.2. Por agrupamientos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "_ = data.boxplot(column='Edad', by='Recuperado', ax=plt.gca())"
   ]
  },
  {
   "source": [
    "## 6. Pruebas de normalidad\n",
    "Hay diferentes [pruebas de normalidad](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3693611/), en este Jupyter Notebook se aplican tres de ellas.\n",
    "### 6.1. Limpieza de datos: eliminación de datos no finitos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.isfinite(data['Edad'])\n",
    "data = data.loc[mask]"
   ]
  },
  {
   "source": [
    "### 6.2. Prueba de [Kolmogorov–Smirnov](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kstest.html)\n",
    "Esta es una prueba no parámetrica para determinar si una cierta muestra sigue una determinada distribución de probabilidad.  Esta prueba cuantifica la distancia entre la función de distribución empírica de una muestra y la función de distribución acumulativa de la distribución de referencia.\n",
    "\n",
    "La hipótesis nula es que los datos analizados siguen la distribución de referencia. Si $p-value \\geq 0.05$, se acepta la hipótesis nula, de lo contrario, se rechaza. \n",
    "#### 6.2.1. Para todos los datos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = stats.kstest(data['Edad'],'norm')\n",
    "print('statiscic: %0.2f, p-value=%0.5g\\n' % (ks.statistic, ks.pvalue))"
   ]
  },
  {
   "source": [
    "#### 6.2.1. Para cada conjunto agrupados por *Recuperado*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recuperado_data = data.groupby('Recuperado')\n",
    "ks_dict = {'status':[], 'statistic':[], 'p':[]} \n",
    "for group, this_data in recuperado_data:\n",
    "    ks = stats.kstest(data['Edad'],'norm')\n",
    "    ks_dict['status'].append(group)\n",
    "    ks_dict['statistic'].append(ks.statistic)\n",
    "    ks_dict['p'].append(ks.pvalue)\n",
    "ks_df = pd.DataFrame(ks_dict)\n",
    "ks_df"
   ]
  },
  {
   "source": [
    "### 6.2. Prueba [Anderson-Darling](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.anderson.html)\n",
    "Esta prueba estadística permite deterimar si una muestra sigue una cierta distribución estadística de referencia.  \n",
    "\n",
    "La hipótesis nula para esta prueba es que los datos corresponden con la distribución de referencia.\n",
    "\n",
    "Si el estadístico es mayor que los valores críticos para los niveles de significancia, entonces, se dice que la hipótesis nula es rechazada.\n",
    "\n",
    "#### 6.3.1. Para todos los datos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = stats.anderson(data['Edad'], dist='norm')\n",
    "ad"
   ]
  },
  {
   "source": [
    "#### 6.3.1. Para cada conjunto agrupados por *Recuperado*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recuperado_data = data.groupby('Recuperado')\n",
    "ad_dict = {'status':[], 'statistic':[]} \n",
    "for group, this_data in recuperado_data:\n",
    "    ad = stats.anderson(data['Edad'], dist='norm')\n",
    "    ad_dict['status'].append(group)\n",
    "    ad_dict['statistic'].append(ad.statistic)\n",
    "    idx = 0\n",
    "    for c in ad.critical_values:\n",
    "        idx += 1\n",
    "        key = 'Critical Value %d' % idx\n",
    "        if not key in ad_dict.keys():\n",
    "            len_status = len(ad_dict['status'])\n",
    "            ad_dict[key] = [] if len_status == 1 else len_status*[np.NaN]\n",
    "        ad_dict[key].append(c)\n",
    "    idx = 0\n",
    "    for s in ad.significance_level:\n",
    "        idx += 1\n",
    "        key = 'Significance Level %d' % idx\n",
    "        if not key in ad_dict.keys():\n",
    "            len_status = len(ad_dict['status'])\n",
    "            ad_dict[key] = [] if len_status == 1 else len_status*[np.NaN]\n",
    "        ad_dict[key].append(s)\n",
    "\n",
    "ad_df = pd.DataFrame(ad_dict)\n",
    "ad_df"
   ]
  },
  {
   "source": [
    "### 6.3. Prueba de [Shapiro-Wilk](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html)\n",
    "\n",
    "Esta prueba estadística permite determinar si los datos siguen una distribución normal.\n",
    "\n",
    "La hipótesis nula es que los datos siguen la distribución normal.  Si $p-value \\geq 0.05$, se acepta la hipótesis nula, de lo contrario, se rechaza.\n",
    "#### 6.3.1. Para todos los datos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic, p = stats.shapiro(data['Edad'])\n",
    "print('statiscic: %0.2f, p-value=%0.5g\\n' % (statistic, p))"
   ]
  },
  {
   "source": [
    "#### 6.3.1. Para cada conjunto agrupados por *Recuperado*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recuperado_data = data.groupby('Recuperado')\n",
    "sw_dict = {'status':[], 'statistic':[], 'p':[]} \n",
    "for group, this_data in recuperado_data:\n",
    "    statistic, p = stats.shapiro(data['Edad'])\n",
    "    sw_dict['status'].append(group)\n",
    "    sw_dict['statistic'].append(statistic)\n",
    "    sw_dict['p'].append(p)\n",
    "sw_df = pd.DataFrame(sw_dict)\n",
    "sw_df"
   ]
  },
  {
   "source": [
    "## 7. Análisis básico de evolución temporal"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_labels = ['fecha reporte web', 'Fecha de notificación', 'Fecha de inicio de síntomas','Fecha de muerte', 'Fecha de diagnóstico', 'Fecha de recuperación']"
   ]
  },
  {
   "source": [
    "### 7.1. Limpieza de datos: conversión de formato y remoción de datos inválidos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_label='Fecha de diagnóstico'\n",
    "date_time_str = data[time_label]\n",
    "for d in date_time_str:\n",
    "    try:\n",
    "        datetime. strptime(d, '%d/%m/%Y %H:%M:%S')\n",
    "    except:\n",
    "        print(d)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_datetime(row, time_label='Fecha de diagnóstico'):\n",
    "    d = row[time_label]\n",
    "    this_data = None\n",
    "    try:\n",
    "        this_data = datetime.strptime(d, '%d/%m/%Y %H:%M:%S')\n",
    "    except:\n",
    "        return np.NaN\n",
    "    return this_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[time_label] = data.apply(to_datetime, axis= 1)\n",
    "mask = ~data[time_label].isna()\n",
    "data = data.loc[mask]"
   ]
  },
  {
   "source": [
    "### 7.2. Línea temporal"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = min(data[time_label])\n",
    "t_serie = data[time_label] - t0\n",
    "data['t [días]'] = [d.days for d in t_serie]"
   ]
  },
  {
   "source": [
    "### 7.3. Submuestreo y gráfica de la columna *Edad* en función del tiempo\n",
    "#### 7.3.1. Submuestreo para graficar solo N muestras"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "data_len = len(data)\n",
    "k = np.arange(0, data_len, int(data_len/N))"
   ]
  },
  {
   "source": [
    "#### 7.3.2. Gráfica para todas las edades"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "plt.plot(data.iloc[k]['t [días]'], data.iloc[k]['Edad'], 'ko')\n",
    "plt.xlabel('Tiempo [días]')\n",
    "_ = plt.ylabel('Edad [años]')"
   ]
  },
  {
   "source": [
    "#### 7.3.2. Gráfica de edades por agrupamiento por *Recuperado*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recuperado_data = data.groupby('Recuperado')\n",
    "plt.figure(dpi=300)\n",
    "marks = 'ov^>'\n",
    "idx = -1\n",
    "for group, this_data in recuperado_data:\n",
    "    data_len = len(this_data)\n",
    "    k = np.arange(0, data_len, int(data_len/N))\n",
    "    idx += 1\n",
    "    plt.plot(this_data.iloc[k]['t [días]'], this_data.iloc[k]['Edad'], marks[idx], label=group)\n",
    "plt.xlabel('Tiempo [días]')\n",
    "plt.ylabel('Edad [años]')\n",
    "_ = plt.legend()"
   ]
  },
  {
   "source": [
    "### 7.4. Medias para cada 30 días\n",
    "#### 7.4.1. Método para obtener las medias mensuales para la *Edad*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_means(df):\n",
    "    t2_array = np.arange(1, int(max(df['t [días]']))+30, 30)\n",
    "    t1_array = t2_array - 1\n",
    "    t = []\n",
    "    mean = []\n",
    "    for t1, t2 in zip(t1_array, t2_array):\n",
    "        mask = (df['t [días]'] >= t1) & (df['t [días]'] < t2)\n",
    "        t.append(t1/30)\n",
    "        mean.append(np.mean(df.loc[mask, 'Edad'].dropna()))\n",
    "    return t, mean"
   ]
  },
  {
   "source": [
    "#### 7.4.2. Método para obtener el número de casos mensuales"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(df):\n",
    "    t2_array = np.arange(1, int(max(df['t [días]']))+30, 30)\n",
    "    t1_array = t2_array - 1\n",
    "    t = []\n",
    "    counts = []\n",
    "    for t1, t2 in zip(t1_array, t2_array):\n",
    "        mask = (df['t [días]'] >= t1) & (df['t [días]'] < t2)\n",
    "        t.append(t1/30)\n",
    "        counts.append(np.count_nonzero(mask.dropna()))\n",
    "    return t, counts"
   ]
  },
  {
   "source": [
    "#### 7.4.2. Gráfica de media de edades por agrupamiento por *Recuperado*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1\n",
    "plt.figure(dpi=300)\n",
    "for group, this_data in recuperado_data:\n",
    "    idx += 1\n",
    "    t, mean = get_means(this_data)\n",
    "    plt.plot(t, mean, marks[idx], label=group)\n",
    "plt.xlabel('Tiempo [meses]')\n",
    "plt.ylabel('Edad [años]')\n",
    "_ = plt.legend()"
   ]
  },
  {
   "source": [
    "#### 7.4.2. Gráfica de casos por agrupamiento por *Recuperado*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1\n",
    "plt.figure(dpi=300)\n",
    "for group, this_data in recuperado_data:\n",
    "    idx += 1\n",
    "    t, counts = get_counts(this_data)\n",
    "    plt.semilogy(t, counts, marks[idx], label=group)\n",
    "plt.xlabel('Tiempo [meses]')\n",
    "plt.ylabel('Edad [años]')\n",
    "_ = plt.legend()"
   ]
  },
  {
   "source": [
    "## 8. Preguntas de autoexplicación\n",
    "### 8.1. Primer conjunto de preguntas de auto explicación\n",
    "\n",
    "8.1.1. En el ítem 1 se importan unas librerías.  Describa, de manera resumida, el propósito de cada librería importada.\n",
    "\n",
    "8.1.2. En el ítem 2 hay dos métodos para cargar los datos, en el primero se cargan desde una carpeta local, que se crea cuando se [clona el repositorio](https://github.com/davidalejandromiranda/StatisticalPhysics.git), y en el segundo, desde un archivo en la nube.  ¿Cuál es el propósito de utilizar *try*.\n",
    "\n",
    "8.1.3. En el ítem 3.1 se describen los datos importados, *data.describe()*, ¿de qué manera los valores de las filas *count*, *mean*, *std*, *min*, *25%*, *50%*, *75%* y *max* describen los datos de cada columna? Se sugiere comparar los ítems 3.1 y 3.4.\n",
    "\n",
    "8.1.4. Los datos importados están organizados por columnas, ¿qué información contienen dichas columnas?\n",
    "\n",
    "8.1.5. Describa cómo se analizan los datos de las columnas *Recuperado* y *Edad*.  Tenga en cuenta que antes de procesar los datos estos son limpiados y luego se realiza el análisis."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 8.2. Segundo conjunto de preguntas de auto explicación\n",
    "\n",
    "8.2.1. Interprete cada una de las pruebas de normalidad aplicadas en el ítem 6.  Se sugiere acompañar la interpretación con los gráficos de violín (ítem 5.2) y los *boxplot* (ítem 5.3) obtenidos.\n",
    "\n",
    "8.2.2. Describa cómo se realiza la limplieza de datos para el análisis temporal, ítem 7.1.\n",
    "\n",
    "8.2.3. En la línea 3 del ítem 7.2 se utiliza el comando *d.days*, ¿cuál es el propósito de utilizar dicho comando?\n",
    "\n",
    "8.2.4. ¿Cuál es el propósito de ralizar un submuestreo de los datos y cómo se realiza?\n",
    "\n",
    "8.2.5. En el ítem 7.4 se analizan los valores medios de datos muestreados para cada 30 días.  Interprete el análisis temporal de *Edad* teniendo en cuenta el agrupamiento por la columna *Recuperado*.\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 8.3. Tercer conjunto de preguntas de autoexplicación\n",
    "\n",
    "8.3.1. ¿Es posible obtener una variable aleatoria normal para describir la *Edad*?  Si su respuesta es afirmativa, muestre cómo se hace.\n",
    "\n",
    "8.3.2. ¿Cuál es la edad media de casos Activos, Fallecidos y Recuperados en los municipios del Área Metropolitana de Bucaramanga?\n",
    "\n",
    "8.3.3. ¿Cuál ha sido el comportamiento en el tiempo de la edad para los casos Activos, Fallecidos y Recuperados en los municipios del Área Metropolitana de Bucaramanga?\n",
    "\n",
    "8.3.4. En los datos importados hay más información de la analizada en este ejemplo.  Presente su propio análisis complementario utilizando una o más celdas de una copia de este Jupyter Notebook.\n",
    "\n",
    "8.3.5. Describa, en sus propias palabras, qué aprendió al resolver las preguntas de autoexplicación de este Jupyter Notebook."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "End!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}